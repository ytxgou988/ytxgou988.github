<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Python | Yuto's Blog]]></title>
  <link href="http://ytxgou988.github.io/blog/categories/python/atom.xml" rel="self"/>
  <link href="http://ytxgou988.github.io/"/>
  <updated>2013-08-20T09:42:05+08:00</updated>
  <id>http://ytxgou988.github.io/</id>
  <author>
    <name><![CDATA[Yuto]]></name>
    <email><![CDATA[ytxgou988@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[爬虫啊爬虫]]></title>
    <link href="http://ytxgou988.github.io/blog/2013/08/19/pa-chong-a-pa-chong/"/>
    <updated>2013-08-19T13:59:00+08:00</updated>
    <id>http://ytxgou988.github.io/blog/2013/08/19/pa-chong-a-pa-chong</id>
    <content type="html"><![CDATA[<p>作为一个Python玩家，爬虫可以说是不得不会的基本功。趁着找工作的需求，学写个BYR论坛招聘信息的爬虫</p>

<hr />

<h3>第三方Python包</h3>

<ul>
<li>Request:Requests包可以代替urllib2库抓取网页信息。正如介绍所说，Requests——HTTP for Humans，Requests比urllib2库更为简洁</li>
<li>BeautifulSoup:BeautifulSoup包用于HTML标签的分析，可以避免复杂的正则表达式</li>
<li>Redis:Redis是一种NoSQL，用于存放抓取的招聘信息</li>
</ul>


<hr />

<h3>网页信息获取</h3>

<p><code>
r = requests.get(host+board+pages, headers=headers)
</code>
首先，先调用requests包的get函数取得网页信息。由于BYR论坛采用动态网页加载，需要加上XMLHttpRequest以取得完整内容。</p>

<h3>标签分析</h3>

<p><code>
soup = BeautifulSoup(r.text)
info = soup.findAll('a', href=re.compile(r"/article/JobInfo/\d+"), title=None)
</code></p>

<p>利用beautifulsoup包对网页源码进行解析，取得帖子的地址与标题。</p>

<p>```
for i in info:</p>

<pre><code>if i.parent.parent.get("class") == "top":
    continue
else:
    url = host + re.findall(href, str(i))[0]
    title = re.findall(r'&gt;(.+)&lt;', str(i))[0]
</code></pre>

<p>```</p>

<p>通过css属性将置顶帖过滤，并将地址补全</p>

<h3>信息储存</h3>

<p><code>
add('url', url+'   '+title)
</code></p>

<p>将取得的信息存到redis的集合(sets)中，可以避免重复</p>

<h3>总结</h3>

<p>这还只是一个初步的抓取功能，后续还需完善信息显示与关键词过滤等功能。</p>

<p>网络爬虫是一个十分实用的工具，值得好好研究。</p>
]]></content>
  </entry>
  
</feed>
